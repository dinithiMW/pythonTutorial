from math import sqrt
import numpy
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_absolute_error, f1_score, roc_auc_score, roc_curve, log_loss,PrecisionRecallDisplay
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn import metrics

np.random.seed(1)
# read CSV file
dataset = pd.read_csv("water.csv", encoding= 'unicode_escape')

print(dataset.shape)
z = dataset['water sample'].value_counts()
print(z)

x = dataset.iloc[:, 7:27]
y = dataset.iloc[:, 5]

#2 histogram
x.hist(figsize=(60,150))
plt.figure().show()

# histogram of y values
y.hist()
plt.show()

# replace missing values
imp = SimpleImputer(missing_values=np.nan, strategy='mean')
imp = imp.fit(x)

x_imp = imp.transform(x)

x_train, x_test, y_train, y_test = train_test_split(x_imp, y, train_size=0.8)

print(x_train.shape, x_test.shape)

le = LabelEncoder()
le = le.fit(y_train)

le_y_train = pd.Series(le.transform(y_train))
print(le_y_train)
print(y_train)

le_y_test = le.transform(y_test)
print(y_test, le_y_test)

model_ANN = MLPClassifier(hidden_layer_sizes=(10, 10, 10), activation='relu', solver='adam', max_iter=250)
model_ANN.fit(x_train, le_y_train)

y_predict = model_ANN.predict(x_test)
print(y_predict)

# performance of the model on the test
corr_matrix = numpy.corrcoef(le_y_test, y_predict)
corr = corr_matrix[0, 1]
R_sq = corr ** 2
print("R_squared is", R_sq)
recall = metrics.recall_score(le_y_test, y_predict)
precision = metrics.precision_score(le_y_test, y_predict)
print("Recall (all 1s predicted right):", round(recall, 2))
print("Precision (confidence when predicting a 1):", round(precision, 2))
print("Detail:")
print("Accuracy is", accuracy_score(le_y_test, y_predict))

# taking root of mean squared error
root_mean_squared_error = sqrt(mean_squared_error(le_y_test, y_predict))
print("RMSE is", root_mean_squared_error)

MAE = mean_absolute_error(le_y_test, y_predict)
print("MAPE is", MAE)

f1 = f1_score(le_y_test, y_predict)
print('F1 score: %f' % f1)

print("Mean squared error", mean_squared_error(le_y_test, y_predict))
print(confusion_matrix(le_y_test, y_predict))
print(classification_report(le_y_test, y_predict))

classes = np.unique(le_y_test)
fig, ax = plt.subplots()
cm = metrics.confusion_matrix(le_y_test, y_predict, labels=classes)
sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Reds, cbar=False)
ax.set(xlabel="Predict", ylabel="True", title="Confusion matrix")
ax.set_yticklabels(labels=classes, rotation=0)
plt.show()

#3accuracy over approaches
plt.plot(le_y_test, color='green', alpha=0.8, label='Train')
plt.plot(y_predict, color='magenta', alpha=0.8, label='Test')
plt.title("Accuracy over epochs", fontsize=14)
plt.xlabel('Epoches')
plt.legend(loc='upper left')
plt.show()

#4auc
auc = roc_auc_score(le_y_test, y_predict)
print('AUC - Test Set: %.2f%%' % (auc*100))

# calculate roc curve
fpr, tpr, thresholds = roc_curve(le_y_test, y_predict)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
plt.xlabel('False positive rate')
plt.ylabel('Sensitivity/ Recall')
# show the plot
plt.show()

#4log loss
accuracy = log_loss(le_y_test, y_predict)
print("Logloss: %.2f" % (accuracy))

